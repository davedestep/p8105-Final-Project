---
title: "Project Report"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(gridExtra)
library(lme4)
library(lubridate)
library(viridis)
library(corrplot)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

*David DeStephano dd2948, Connor Goldman cg3112, Sarah Munro sim2128, RuiJun Chen rc3179*
*Dec 5, 2019*

<br>

# Motivation

Human health is inextricably linked to the quality of the air we breath we every day. Outdoor air comprises a significant portion of our lifetime air exposure, and the quality of that air has been declining for some time. Air pollution is increasingly recognized as a factor contributing to global morbidity and mortality, particularly with respect to cardiovascular and respiratory health. In 2018, The World Health Organization released a report stating that:

	→ 91% of the world population lived in places where WHO air quality guidelines were not met 
	→ Air pollution was estimated to cause 4.2 million premature deaths worldwide in 201
  → Reduction in pollution would reduce the global burden of disease from heart disease, stroke, lung cancer, and chronic and acute respiratory diseases 

**From [WHO](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health)

# Goals
There is a long way to go in improving ambient air quality, but there is a lot to be gained in doing so. Improved monitoring of factors that influence pollution, and increased awareness of associated health risks can advance the road to recovery. Through this project we strive to:

	→ Replicate an air quality monitoring system that could be utilized by a government or health entity 
	→ Assess meteorological data as a predictor of air quality
	→ Identify temporal trends, if any 
	→ Look for associations between air quality and cardiovascular health 

# Related Work
After finding the dataset, we performed a literature review and were inspired by several studies to examine predictors of PM 2.5 and whether pollutants affect CVD hospitalizations. There has been some evidence that air pollutants such as PM10, nitroden diaxide (NO2), and carbon monoxide (CO) contribute to cardiovascular disease and related deaths [Nature](https://www.nature.com/articles/jes201621.pdf?origin=ppub). We wanted to examine this relationship when taking into account meteorological and temporal factors, as there has been a link between time of year and temperature with the occurence of heart attack.    

# Initial Questions



# Our Data
Beijing is one of the industrial capitals of the world, and a notorious source of air pollution. For our primary analyses we looked at a dataset describing meteorological and air quality data from 12 sites in Beijing, China over the years 2013 - 2017. This data comes from [The UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php). Air quality was measured as a concentration of particulate matter 2.5 (PM2.5) and particulate matter 10 (PM10). PM2.5 is associated with greater health risks, because the smaller size (<2.5um) makes it more efficient at penetrating deeper into the respiratory system. For this reason we chose to analyze PM2.5 as the outcome of interest. (https://www3.epa.gov/ttn/amtic/files/ambient/pm25/spec/drispec.pdf). 


Our air pollution dataset included the following variables:

* No: row number
* year: year of data in this row
* month: month of data in this row
* day: day of data in this row
* hour: hour of data in this row
* PM2.5: PM2.5 concentration (ug/m^3)
* PM10: PM10 concentration (ug/m^3)
* SO2: SO2 concentration (ug/m^3)
* NO2: NO2 concentration (ug/m^3)
* CO: CO concentration (ug/m^3)
* O3: O3 concentration (ug/m^3)
* TEMP: temperature (degree Celsius)
* PRES: pressure (hPa)
* DEWP: dew point temperature (degree Celsius)
* RAIN: precipitation (mm)
* wd: wind direction
* WSPM: wind speed (m/s)
* station: name of the air-quality monitoring site


For our secondary analyses, we sought to isolate any associations between air quality and health outcomes in Beijing. We modeled acute myocardial infarction (AMI) as the outcome using the dataset from [Liu et al.](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204706). The data was collected by the public health information center of Beijing, and includes AMI hospital admissions in Beijing for each month between January 1, 2013 and December 31, 2016.

The following variables were included:

* Gender	
* Admission date(year)	
* Admission date(month)	
* Main discharge diagnosis


# Exploratory Analysis
### Loading and tidying the data
We loaded the data from csv files obtained from the data archive listed above

```{r, results='hide', message=FALSE}
files = list.files("./PRSA_Data_20130301-20170228", full.names = TRUE)

all_df = map_df(files, read_csv) %>% 
  bind_rows() %>% 
  janitor::clean_names()
```

We identified a total of `r all_df %>% nrow()` rows/observations, and a total of `r all_df %>% ncol()` variables or columns which include the following: `r all_df %>% tbl_vars()`. We then wanted to characterize the amount of data present and missing for each variable:

Total amount of data:
```{r}
colSums(!is.na(all_df))
```

Amount of missing data for each variable:
```{r}
colSums(is.na(all_df))
```

From this, it appears that all observations(rows) have date, time, and station information. The number of complete observations with all variables filled in is `r all_df %>% complete.cases() %>% sum` which represents the vast majority of the observations. 

In tidying the data, we found there is a column/variable 'no' which just seems to count rows, which is not needed and removed. We also changed wd and station into factors, added seasons, and created a variable for seasonal years (since winter spans over two years, this variable was created to only be coded as the year in which winter began). Date and datetime variables were also created.
    
```{r}
all_df = 
  all_df %>% 
  select(-no) %>% 
  mutate(
    wd = as.factor(wd),
    station = as.factor(station),
    date = as.Date(str_c(year, '-', month, '-', day)),
    datetime = as.POSIXct(str_c(year, '-', month, '-', day, ' ', "00:", hour,":00")),
    season = case_when(
      (month < 3) ~ "winter", #start of Spring is 3/20
      (month == 3 & day < 20) ~ "winter",
      (month < 6) ~ "spring", #start of Summer is 6/21
      (month == 6 & day < 21) ~ "spring",
      (month < 9) ~ "summer", #start of Fall is 9/22
      (month == 9 & day < 22) ~ "summer",
      (month < 12) ~ "fall", #start of Winter is 12/21
      (month == 12 & day < 21) ~ "fall",
      (month == 12 & day >= 21) ~ "winter"
    ),
    seasonal_year=if_else(month<4 & season=="winter" & year ==2014, 2013,
                          if_else(month < 4 & season=="winter" & year ==2015, 2014,
                           if_else(month < 4 & season=="winter" & year ==2016, 2015,
                            if_else(month < 4 & season=="winter" & year ==2017, 2016, year)))),
    season_and= paste(season, " ", seasonal_year)
  )
```

Visualizing the missing data over time
```{r}
missing = all_df %>% 
  select(-year, -season, -seasonal_year, -season_and, -datetime, -month, -day, -hour) %>% #the original data except the ones we know are complete
  is.na() %>% 
  as_tibble() %>% 
  mutate(
    date = all_df$date,
    station = all_df$station
  ) %>% 
  pivot_longer(
    cols = pm2_5:wspm
  ) 

missing %>% 
  ggplot(aes(x =date, y = name, fill = value)) + 
  geom_raster(alpha=0.8) + 
  scale_fill_discrete(name = "", labels = c("Present", "Missing")) +
  labs(x = "Variable",y = "Date", title = "Missing values over time") +
  coord_flip() 
```

And now visualizing missing data over time across stations:
```{r}
missing %>% 
  ggplot(aes(x =date, y = name, fill = value)) + 
  geom_raster(alpha=0.8) + 
  scale_fill_discrete(name = "", labels = c("Missing", "Present")) +
  labs(x = "Time",y = "Variable", title = "Missing values over time by station") +
  facet_grid(station~.) 
```

Our primary outcome of interest is PM2.5, and can be summarized as follows:

```{r}
all_df %>% pull(pm2_5) %>% summary
```

###Looking at PM2.5 over time:
```{r}

summary
all_df %>% 
  ggplot(aes(x = date, y = pm2_5)) +
  geom_point() +
  geom_smooth()
```

###Looking at PM2.5 over time by station:
```{r}
all_df %>% 
  ggplot(aes(x = date, y = pm2_5)) +
  geom_point() +
  geom_smooth() +
  facet_grid(~station)
```

###Looking at PM2.5 by seasons:
```{r}
all_df %>% 
  mutate(
    fct_reorder(season, pm2_5)
  ) %>% 
  ggplot(aes(x = season, y = pm2_5)) + 
  geom_boxplot()
```

###Kind of hard to distinguish, will try limiting scale of y-axis and try a violin plot
```{r}
all_df %>% 
  mutate(
    fct_reorder(season, pm2_5)
  ) %>% 
  ggplot(aes(x = season, y = pm2_5)) + 
  geom_boxplot() + 
  ylim(0, 250)

all_df %>% 
  mutate(
    fct_reorder(season, pm2_5)
  ) %>% 
  ggplot(aes(x = season, y = pm2_5)) + 
  geom_violin() + 
  ylim(0, 250)


```
Overall seems fairly similar across seasons, but technically highest in the winter with a number of very high outlier values as well

###Average PM 25 by year for all stations
```{r}
all_df %>%  
  group_by(year) %>% 
  summarize(avg_pm25=mean(pm2_5, na.rm = TRUE)) %>% 
  ggplot(aes(x=year, y=avg_pm25)) +
  geom_line()
```


###Average PM 25 by year for each station
```{r}
all_df %>%  
  group_by(year, station) %>% 
  summarize(avg_pm25=mean(pm2_5, na.rm = TRUE)) %>% 
  ggplot(aes(x=year, y=avg_pm25, color=station, group=station)) +
  geom_line()
```

We can see that each individual station seems to follow the same yearly average pm 2.5 trend

###Average PM 25 by year and season for each station
```{r}
all_df %>%  
  group_by(season, seasonal_year, station) %>% 
  summarize(avg_pm25=mean(pm2_5, na.rm = TRUE)) %>% 
  ggplot(aes(x=season, y=avg_pm25, color=station, group=station)) +
  geom_line()+
  facet_wrap(seasonal_year~.) +
  ggtitle("Average PM2.5 by Seasonal Years")
```

###Average PM 25 by year and season for each station
```{r}
all_df %>%  
  mutate(season_and=factor(season_and, levels = c("spring   2013", "summer   2013", "fall   2013", "winter   2013",
                                                  "spring   2014", "summer   2014", "fall   2014", "winter   2014",
                                                  "spring   2015", "summer   2015", "fall   2015", "winter   2015",
                                                  "spring   2016", "summer   2016", "fall   2016", "winter   2016"))) %>% 
  group_by(season_and, station) %>% 
  summarize(avg_pm25=mean(pm2_5, na.rm = TRUE)) %>% 
  ggplot(aes(x=season_and, y=avg_pm25, color=station, group=station)) +
  geom_line()+
  ggtitle("Average PM2.5 by Seasonal Years") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
#need to change wspm to CUMULATIVE wind speed for month or direction
all_df %>%  
  filter(station=="Dingling") %>% 
  ggplot(aes(x=dewp, y=wspm, color=pm2_5)) +
  geom_point(alpha=0.10) +
  scale_color_gradient(low="blue", high="red")

```

## Motherload of all scatterplots (Plotting everything )
Looking at scatter plots of every variable against PM2.5 to look for potential correlation
```{r, eval=FALSE} 
## Just FYI, this takes a long time to run. And the plots will take up 900MB of memory
#So for now I've set eval=false, but I'm pushing the image it generated, called all_variables_plot.png
par(mfrow = c(4, 5))

vars = all_df %>% select(-pm2_5, -year, -month, -day, -date, -season) %>% colnames()
plots = list()
for (i in 1:length(vars)) {
  plots[[i]] = ggplot(all_df, aes_string(x = vars[i], y = "pm2_5")) + geom_point()
}
do.call(grid.arrange, plots)
```
![all variables scatterplots](all_variables_plot.png){width=600px}

##Pearson Correlation Coefficients:

```{r}
all_df %>% 
  select(-wd, -station, -date, -datetime, -season, -seasonal_year, -season_and, -hour, -year, -month, -day) %>% 
  map(as.numeric) %>% 
  as.data.frame() %>% 
  cor(use = "complete.obs") %>% 
  corrplot(method = "square", addCoef.col = "black", tl.col="black", tl.srt=45, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE, number.cex = .7)
```


Temperature is correlated with our pollutant concentration, which are all also correlated with eachother, while windspeed has the most effect on decreasing the concentration of these pollutants.

Variables which seem correlated with PM2.5 include (not surprisingly) PM10, but also rain, wind speed, o3 all seem to be strongly correlated. In addition, no2, so2, and possibly temperature, pressure and dew point but in a non-linear fashion

## Findings
We looked at correlations between PM2.5 and the meteorological variables, including dewpoint, windspeed...
Correlations..
Scatterplots
Spearman's correlation coefficients to evaluate the inter-relations between air pollutants and weather conditions
Ray
 
# Additional Analysis
Three models were developed for analysis of weather conditions and their association with PM2.5. A multivariable linear regression, a mixed model, and a Mixed Model for Longitudinal Continuous Data were developed to examine the variables of interest.

Almost every variable is significant, however, station, windspeed, season, and windspeed all have high effect sizes.
Rain, dewpoint, temp also have moderate effect sizes.
 
CVD model… whatever we decide on

##Is pm 2.5, season, NO2, or CO associated with CVD?
Poisson regression..
	Use the following articles:
		https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204706
https://www.nature.com/articles/7500453.pdf?origin=ppub

##What meteorological variables influence PM 2.5?
###Even though predictors are not independent, will model using linear regression before a longitudinal model  
```{r}
###Remove timeseries variables:
reg<-all_df %>% select(-date,-datetime, -month,-day,-hour)

full <- lm(pm2_5 ~ ., data = reg)

tab<-full %>% broom::tidy()
knitr::kable(tab, digits = 3)

```


###Mixed Model
```{r}
all_df %>% 
  lme4::lmer(pm2_5 ~ year + season + so2 + no2 + co + o3 + temp + dewp + rain + wd + wspm + (1 | station), data = .) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

```


### Mixed Model for Longitudinal Continuous Data
```{r}
mixed<-all_df %>% 
  lme4::lmer(pm2_5 ~ year + season + so2 + no2 + co + o3 + temp + dewp + rain + wd + wspm + datetime + (1 | station), data = .) 

mixed %>% broom::tidy() %>% knitr::kable(digits = 3)

```








####################################################
####################################################
#Linking to health data
####################################################
####################################################

```{r}
cvd<-read_csv("./patient_mi_data/patients_mi.csv") %>% janitor::clean_names()

cvd2<- cvd %>% 
  group_by(admission_date_year, admission_date_month, gender) %>% 
  summarise(n = n()) %>% 
  rename(year=admission_date_year) %>%
  rename(month=admission_date_month)

pollution<-all_df %>%
  group_by(year, month) %>% 
  summarize(avg_pm2_5=mean(pm2_5, na.rm=TRUE),
            avg_co=mean(co, na.rm=TRUE),
            avg_temp=mean(temp, na.rm=TRUE))

model_data <- left_join(pollution, cvd2, by=c("year", "month")) %>% 
  na.omit() 
```

```{r}
model_data %>%  
  ggplot(aes(x=month, y=n, color=avg_pm2_5, group=gender)) +
  geom_line()+
  geom_point(aes(size = avg_co))+
  scale_color_viridis(option = "B")+
  facet_wrap(year~.) +
  ggtitle("Number of MI's by PM2.5 and Year/Month") 


```



```{r}
model_data %>%  
  ggplot(aes(x=month, y=n, color=avg_pm2_5, group=gender)) +
  geom_line()+
  geom_point()+
  scale_color_viridis(option = "B")+
  facet_wrap(year~.) +
  ggtitle("Average PM2.5 by Years")
```

```{r}
model_data %>%  
  ggplot(aes(x=month, y=n, color=avg_co, group=gender)) +
  geom_line()+
  geom_point()+
  scale_color_viridis(option = "B")+
  facet_wrap(year~.) +
  ggtitle("Number of MI's by Carbon Monoxide and Year/Month")
```




It does appear the hospitalizations are higher in winter months. Unfortunately, we will not be able to draw strong conclusions about the effect pollution on heart attacks since it is so strongly correlated with the month/season. We can try to control for temperature instead of month?

```{r}
model_data %>%  
  ggplot(aes(x=month, y=n, color=avg_temp, group=gender)) +
  geom_line()+
  geom_point()+
  scale_color_viridis(option = "B")+
  facet_wrap(year~.) +
  ggtitle("Number of MI's by Temperature and Year/Month")
```




We have to use month because we have no data on days of the month to separate analysis into seasons.

The count data we are using is the number of people admitted for MI per month.

We could use a rate for the population of beijing for each year (and month), but from 2014 to 2018, the annual growth rate has been 0.3 percent. Beijing's population peaked at 21.73 million residents in 2016.
[Source](https://www.newgeography.com/content/006258-beijing-and-shanghai-limit-population-growth). For this reason (population numbers have been fairly flat) we decided to just use pure count data.
```{r}
model_data<-model_data%>% 
  mutate(month=factor(month))

summary(m1 <- glm(n ~ avg_pm2_5 + avg_co + avg_temp + month + year + gender + avg_pm2_5*avg_temp + avg_co*avg_temp, family="poisson", data=model_data))

tab<-m1 %>% broom::tidy()
knitr::kable(tab, digits = 3)

```


#Remove month and year
```{r}
m1 <- glm(n ~ avg_pm2_5 + avg_co + avg_temp + gender, family="poisson", data=model_data)

tab<-m1 %>% broom::tidy()
knitr::kable(tab, digits = 6)



m2 <- glm(n ~ avg_pm2_5 + avg_co + avg_temp + gender + avg_pm2_5*avg_temp + avg_co*avg_temp, family="poisson", data=model_data)

tab<-m2 %>% broom::tidy()
knitr::kable(tab, digits = 6)

```


#Could it be that 2016 was an outlier and had a huge number of MI's?
```{r}
model_data2<-model_data %>% 
  filter(year!=2016)

m1 <- glm(n ~ avg_pm2_5 + avg_co + avg_temp + gender, family="poisson", data=model_data2)

tab<-m1 %>% broom::tidy()
knitr::kable(tab, digits = 6)




m2 <- glm(n ~ avg_pm2_5 + avg_co + avg_temp + gender + avg_pm2_5*avg_temp + avg_co*avg_temp, family="poisson", data=model_data2)

tab<-m2 %>% broom::tidy()
knitr::kable(tab, digits = 6)

```



	
	
	
	
	
	
# Discussion
Insights
